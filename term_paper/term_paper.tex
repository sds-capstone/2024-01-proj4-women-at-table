% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage[]{natbib}
\usepackage{textcomp}


%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%

%% load any required packages here



% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}




\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\hypersetup{
  pdftitle={Maximizing Fairness with Synthetic data: Access to Emergency Fund in Sub-Saharan Africa},
  pdfkeywords={Fairness; predictive machine learning; emergency funds;
financial inclusion; ethics; gender bias; debiasing; synthetic data;
Sub-Saharan Africa; fairness metrics; Global Financial Inclusion
Database},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Maximizing Fairness with Synthetic data: Access to
Emergency Fund in Sub-Saharan Africa}

  \author{
        Charavee Basnet Chettri \\
    \\
     and \\     Vivian Wei \\
    \\
     and \\     Betty Pu \\
    \\
     and \\     Ziyue Yang \thanks{We are grateful to the Women at the
Table team and Sofia Kypraiou for the project inspiration and suggesting
the path forward} \\
    Department of Statistical and Data Sciences, Smith College,
Northampton MA\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Maximizing Fairness with Synthetic data: Access to
Emergency Fund in Sub-Saharan Africa}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Financial inclusion is paramount for economic stability and resilience,
particularly in diverse regions like Sub-Saharan Africa, spanning low to
high-income countries and encompassing both resource-intensive and
non-resource-intensive economies. This study focuses on a crucial aspect
of financial resilience: the accessibility of emergency funds, defined
as having access to 1/20 of Gross National Income (GNI) per capita in
local currency within 30 days. Leveraging previous colleagues'
exploratory work on the Global Financial Inclusion Database 2021, our
objective is to mitigate inherent gender biases in the dataset by
rebalancing it with synthetic data, thereby enhancing fairness in
predicting emergency fund accessibility. Through predictive machine
learning modeling, we aim to contribute to the economic empowerment of
individuals in Sub-Saharan Africa, ultimately fostering resilience and
reducing disparities in access to essential financial resources.
\end{abstract}

\noindent%
{\it Keywords:} Fairness; predictive machine learning; emergency funds;
financial inclusion; ethics; gender bias; debiasing; synthetic data;
Sub-Saharan Africa; fairness metrics; Global Financial Inclusion
Database

\vfill

\newpage
\spacingset{1.9} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In the realm of financial inclusion, the accessibility of emergency
funds plays a pivotal role in determining an individual's financial
stability and resilience, especially in developing
countries.\citep{10.1093/oso/9780198827535.003.0007} In this project,
our goal is to predict the possibility for people in Sub-Saharan African
countries to come up with emergency funds, defined as 1/20 of GNI per
capita in local currency, within a 30-day
period\citep[@][]{Demirguc-Kunt2022}. This prediction serves as a
crucial factor for establishing future public financial policies, such
as determining the eligibility of individuals for loans and financial
assistance. The significance of this problem lies within its direct
impact on the economic well-being and empowerment of individuals in
developing regions. According to the
\href{https://www.worldbank.org/en/publication/globalfindex}{Global
Financial Inclusion (Global Findex) Database 2021} published by the
World Bank, only a little over half of people over 15 years of age in
developing economies could access extra funds within 30 days if faced
with unexpected expenses \citep{Demirguc-Kunt2022}. Therefore, there is
a pressing need to understand the factors influencing this accessibility
and eliminate inherent bias in the dataset. By delving into this issue,
we not only contribute to enhancing financial inclusion but also aid in
mitigating the different effects of financial shocks on vulnerable
populations.

Defining fairness is essential since the concept itself is relative
among different people. In the data science discourse, fairness
encompasses three key aspects: individual fairness, group fairness, and
causal fairness\citep{Kypraiou2021What}. Individual fairness focuses on
preventing discrimination against individuals with similar relevant
characteristics. This means ensuring that individuals in similar
situations receive similar outcomes from the model, regardless of
irrelevant factors\citep{10.1145/3461702.3462621}. Group fairness aims
to prevent disparities in outcomes for different groups. This ensures
equal opportunities for all groups, regardless of their
membership\citep{10.1145/3442188.3445876}. Causal fairness goes beyond
simply observing disparities and delves into understanding their
underlying causes. It seeks to mitigate these root causes to achieve
fair outcomes within and across groups\citep{plecko2022causal}.

Our previous colleagues conducted analysis using the \textless AI \&
Equality\textgreater{} Human Rights Toolbox and used a Decision Tree
Classifier machine learning model implemented via Python to predict
access to emergency funds with 68\% accuracy. Their work laid a solid
foundation by exploring demographic and financial variables within the
dataset, and assessed the fairness of the decision tree classifier,
particularly concerning gender bias, and then applied various processing
techniques to enhance the fairness of the model\citep{Porta2022}.

Based on their work, our group aims to incorporate synthetic data to
rebalance the dataset, ensuring equitable representations amongst both
genders in the dataset. Our approach aims to consider a broader
selection of machine learning algorithms and mitigate the disparities
the previous colleagues found in the decision tree's classifier's
predictions and enhance fairness with synthetic data, ultimately better
predict access to emergency funds in south-Saharan Africa
countries\citep{SyntheticDataAIEquality}.

\bibliographystyle{plain}
\bibliography{bibliography.bib}



\end{document}
